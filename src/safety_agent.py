"""
å®‰å…¨å®¡æŸ¥æ™ºèƒ½ä½“ - åŸºäº LLM + RAG + RDKit
ç»¼åˆæ£€ç´¢åˆ°çš„è§„åˆ™å’Œåˆ†å­ç»“æ„åˆ†æç»“æœï¼Œç”ŸæˆåŒ–å­¦å®‰å…¨å®¡æŸ¥æŠ¥å‘Š
"""
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from .chem_tools import ChemAnalyzer
from .rag_engine import get_retriever

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# System Prompt
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªåŒ–å·¥å®‰å…¨ä¸“å®¶ã€‚è¯·æ ¹æ®ã€æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“è§„åˆ™ã€‘å’Œã€åˆ†å­ç»“æ„åˆ†æç»“æœã€‘ï¼Œå®¡æŸ¥ç”¨æˆ·çš„åˆæˆæ–¹æ¡ˆã€‚

ä½ çš„èŒè´£ï¼š
1. ä»”ç»†åˆ†ææ£€ç´¢åˆ°çš„æ¯ä¸€æ¡è§„åˆ™ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ç”¨æˆ·çš„æ–¹æ¡ˆç›¸å…³
2. ç»“åˆåˆ†å­ç»“æ„åˆ†æç»“æœï¼ˆå¦‚ç¡åŸºæ•°é‡ã€å æ°®åŸºå›¢ã€è¿‡æ°§é”®ç­‰ï¼‰ï¼Œè¯„ä¼°é£é™©ç­‰çº§
3. å¦‚æœå‘ç°è¿è§„æˆ–é«˜é£é™©ï¼Œå¿…é¡»ç›´æ¥ç»™å‡ºåˆ¤å®šï¼š
   - ğŸ”´ çº¢ç‰Œæ‹¦æˆªï¼šå­˜åœ¨ä¸¥é‡å®‰å…¨éšæ‚£ï¼Œå¿…é¡»ç«‹å³åœæ­¢
   - ğŸŸ¡ é»„ç‰Œè­¦å‘Šï¼šå­˜åœ¨æ½œåœ¨é£é™©ï¼Œéœ€è¦é‡‡å–é¢å¤–é˜²æŠ¤æªæ–½
   - ğŸŸ¢ ç»¿è‰²é€šè¿‡ï¼šæœªå‘ç°æ˜æ˜¾å®‰å…¨é—®é¢˜
4. å¿…é¡»å¼•ç”¨çŸ¥è¯†åº“åŸæ–‡ä½œä¸ºä¾æ®
5. ç»™å‡ºå…·ä½“çš„å®‰å…¨å»ºè®®

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œæ ¼å¼åŒ–è¾“å‡ºå®¡æŸ¥æŠ¥å‘Šã€‚"""


def _get_llm() -> ChatOpenAI:
    """è·å– LLM å®ä¾‹ï¼ˆInternLM / OpenAI å…¼å®¹æ¥å£ï¼‰"""
    return ChatOpenAI(
        model=os.getenv("LLM_MODEL", "intern-latest"),
        openai_api_base=os.getenv("OPENAI_API_BASE", "https://chat.intern-ai.org.cn/api/v1"),
        openai_api_key=os.getenv("OPENAI_API_KEY", ""),
        temperature=0,
        max_tokens=2048,
    )


def review_plan(user_input: str, smiles: str = None) -> str:
    """
    ç»¼åˆå®¡æŸ¥å…¥å£ï¼š
    1. ç”¨ RDKit åˆ†æåˆ†å­ç»“æ„ï¼ˆå¦‚æœæœ‰ SMILESï¼‰
    2. ç”¨ RAG æ£€ç´¢ç›¸å…³å®‰å…¨è§„åˆ™
    3. æ‹¼è£… Prompt å‘ç»™ LLM ç”Ÿæˆå®¡æŸ¥æŠ¥å‘Š

    Args:
        user_input: ç”¨æˆ·çš„åˆæˆæ–¹æ¡ˆæè¿°
        smiles: å¯é€‰çš„ç›®æ ‡åˆ†å­ SMILES

    Returns:
        LLM çš„å®‰å…¨å®¡æŸ¥æŠ¥å‘Š
    """
    # ---- 1. ç»“æ„åˆ†æ ----
    structure_info = ""
    if smiles:
        analyzer = ChemAnalyzer()
        result = analyzer.analyze(smiles)
        structure_info = f"\nã€åˆ†å­ç»“æ„åˆ†æç»“æœã€‘\n{result['summary']}\n"

    # ---- 2. RAG æ£€ç´¢ ----
    retriever = get_retriever(k=5)
    # ç”¨ç”¨æˆ·è¾“å…¥ + SMILESï¼ˆå¦‚æœ‰ï¼‰åšæ£€ç´¢
    query = user_input
    if smiles:
        query += f" (åˆ†å­SMILES: {smiles})"
    docs = retriever.invoke(query)

    retrieved_rules = "\n".join(
        [f"è§„åˆ™{i+1}: {doc.page_content}" for i, doc in enumerate(docs)]
    )

    # ---- 3. æ‹¼è£… Prompt ----
    user_message = f"""
## ç”¨æˆ·æäº¤çš„åˆæˆæ–¹æ¡ˆ

{user_input}

{structure_info}

## æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“è§„åˆ™

{retrieved_rules}

---
è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆå®‰å…¨å®¡æŸ¥æŠ¥å‘Šã€‚
"""

    # ---- 4. è°ƒç”¨ LLM ----
    llm = _get_llm()
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=user_message),
    ]
    response = llm.invoke(messages)
    return response.content
